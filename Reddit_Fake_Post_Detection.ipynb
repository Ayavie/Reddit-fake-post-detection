{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOf7bKlYt5gBkEEjemV9eIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayavie/Reddit-fake-post-detection/blob/main/Reddit_Fake_Post_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDS8umGjfE1I"
      },
      "source": [
        "# ✔️ Problem Formulation:\n",
        "\n",
        "The objective is to find out whether a Reddit post is fake or not. NLP techniques is used to handle this problem. The challenges is to find the best way of preprocessing techniques of posts and also type of vectorization used to indicate the importance of each word/feature. The impact could be having much less fake posts by banning the fake ones.\n",
        "\n",
        "The ideal solution is finding model with accuracy with at least 70% success rate."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Strategy used:\n",
        "1. Trying different classifiers.\n",
        "2. Try the best one with word and vector vectorizers also RandomSearch was used to help find better hyperparameter values.\n",
        "3. Try different preprocessing techniques with RandomSearch with the best model and best vectorizer.\n",
        "4. Try XGBoost with RandomSearch.\n"
      ],
      "metadata": {
        "id": "Sa5Q0rvelXBS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGFrQlWtfcBX"
      },
      "source": [
        "#Importing Libraries and investigating data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suKO4njleR3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc64c02-dbd9-41a7-f4ad-c9aadecd087a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.68)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.4)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "! pip install contractions\n",
        "import contractions\n",
        "! pip install unidecode\n",
        "import unidecode\n",
        "\n",
        "# some seeting for pandas \n",
        "\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2880nx6AfI53"
      },
      "outputs": [],
      "source": [
        "# Reading the training \n",
        "df_main=pd.read_csv('xy_train.csv')\n",
        "\n",
        "#Make a copy of the original training dataframe for usage\n",
        "df=df_main.copy()\n",
        "\n",
        "# Reading testing data\n",
        "df_test=pd.read_csv('x_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIkoc0VXgYA-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d11244f5-0272-4a0f-83c1-12cc35bc866f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  265723   \n",
              "1  284269   \n",
              "2  207715   \n",
              "3  551106   \n",
              "4    8584   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \n",
              "0    0.0  \n",
              "1    0.0  \n",
              "2    0.0  \n",
              "3    0.0  \n",
              "4    0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02455bde-f2b0-4a50-bbb0-616646083f69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02455bde-f2b0-4a50-bbb0-616646083f69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02455bde-f2b0-4a50-bbb0-616646083f69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02455bde-f2b0-4a50-bbb0-616646083f69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Printing few lines of the data\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZKaFxFZhDYX"
      },
      "source": [
        "#Data cleaning and preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtGold3MhA0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9c0b4c-3ece-4a79-ad56-47c273b47eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Init the Wordnet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text,stem,for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    # compile regular expression and return pattern object\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "\n",
        "\n",
        "    for word in word_tokens:\n",
        "      #convert words to lower case\n",
        "      word.lower()\n",
        "      #remove accented words\n",
        "      #unidecode.unidecode(word)\n",
        "      #split words like don't to do not\n",
        "      #contractions.fix(word)\n",
        "\n",
        "\n",
        "    if for_embedding:\n",
        "        # no stemming, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "        \n",
        "    else:\n",
        "      if stem==True:\n",
        "        words_filtered = [stemmer.stem(word) for word in word_tokens if word not in stop_words ]\n",
        "      elif stem==False:\n",
        "        words_filtered =[lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words]\n",
        "      else:\n",
        "        words_filtered = word_tokens\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Testing clean_text function\n",
        "\n",
        "print(clean_text(\"Python is my favorite   programming language!!\", stem=None)) # No stemming or lemmetization\n",
        "print(clean_text(\"Python is my favorite   programming language!!\", stem=True)) # Applied stemming\n",
        "print(clean_text(\"Python is my favorite   programming language!!\", stem=False)) # Applied lemmatization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouq478pV3ocq",
        "outputId": "cf00b682-f49b-48fe-f3e5-7727f6f659de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is my favorite programming language\n",
            "python favorit program languag\n",
            "Python favorite programming language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll try the three different preprocessing techniques and let's see how this works out.\n",
        "\n",
        "\n",
        "Let's try with no stemming or lemmatization."
      ],
      "metadata": {
        "id": "a-FsOJJT4Xv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Clean Comments \n",
        "df[\"text_clean\"] = df.loc[df_main[\"text\"].str.len() > 10, \"text\"]\n",
        "df[\"text_clean\"] = df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x,stem=None, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngoRF86O30As",
        "outputId": "896a3d37-3cfa-4e4d-c00b-a7367f29218d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.9 s, sys: 89.5 ms, total: 16 s\n",
            "Wall time: 21.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "7LtvppDr5AR6",
        "outputId": "262779b7-a2f2-4045-bc57-5abf94067311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "51016  551985   \n",
              "51017  294811   \n",
              "51018  462648   \n",
              "51019  335340   \n",
              "51020  509616   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "51016           British general Jeffrey Amherst Giving smallpox blankets to area natives, colorized (1736)   \n",
              "51017           If The Zombie Apocalypse Happens, This Is Where Scientists Say You Should Go | The Rockies   \n",
              "51018           \"The I.W.W. is Coming! Join The One Big Union\", Industrial Workers of the World, USA, 1907   \n",
              "51019           Why the Viral United Airlines Video Kept Getting Deleted From Reddit | It depicts violence   \n",
              "51020                              American soldier shortly after being beheaded in a Japanese prison camp   \n",
              "\n",
              "       label  \\\n",
              "0        0.0   \n",
              "1        0.0   \n",
              "2        0.0   \n",
              "3        0.0   \n",
              "4        0.0   \n",
              "...      ...   \n",
              "51016    0.0   \n",
              "51017    0.0   \n",
              "51018    0.0   \n",
              "51019    0.0   \n",
              "51020    NaN   \n",
              "\n",
              "                                                                                                text_clean  \n",
              "0      group of friends began to volunteer at homeless shelter after their neighbors protested Seeing a...  \n",
              "1      British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...  \n",
              "2      In Goodyear released kit that allows PS to be brought to heel https youtube com watch ALXulk cg ...  \n",
              "3      Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...  \n",
              "4      Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...  \n",
              "...                                                                                                    ...  \n",
              "51016                   British general Jeffrey Amherst Giving smallpox blankets to area natives colorized  \n",
              "51017              If The Zombie Apocalypse Happens This Is Where Scientists Say You Should Go The Rockies  \n",
              "51018                             The is Coming Join The One Big Union Industrial Workers of the World USA  \n",
              "51019             Why the Viral United Airlines Video Kept Getting Deleted From Reddit It depicts violence  \n",
              "51020                                American soldier shortly after being beheaded in Japanese prison camp  \n",
              "\n",
              "[51021 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fda78111-1ca0-4936-a72a-d6273ed234b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>group of friends began to volunteer at homeless shelter after their neighbors protested Seeing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In Goodyear released kit that allows PS to be brought to heel https youtube com watch ALXulk cg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51016</th>\n",
              "      <td>551985</td>\n",
              "      <td>British general Jeffrey Amherst Giving smallpox blankets to area natives, colorized (1736)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>British general Jeffrey Amherst Giving smallpox blankets to area natives colorized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51017</th>\n",
              "      <td>294811</td>\n",
              "      <td>If The Zombie Apocalypse Happens, This Is Where Scientists Say You Should Go | The Rockies</td>\n",
              "      <td>0.0</td>\n",
              "      <td>If The Zombie Apocalypse Happens This Is Where Scientists Say You Should Go The Rockies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51018</th>\n",
              "      <td>462648</td>\n",
              "      <td>\"The I.W.W. is Coming! Join The One Big Union\", Industrial Workers of the World, USA, 1907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>The is Coming Join The One Big Union Industrial Workers of the World USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51019</th>\n",
              "      <td>335340</td>\n",
              "      <td>Why the Viral United Airlines Video Kept Getting Deleted From Reddit | It depicts violence</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Why the Viral United Airlines Video Kept Getting Deleted From Reddit It depicts violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51020</th>\n",
              "      <td>509616</td>\n",
              "      <td>American soldier shortly after being beheaded in a Japanese prison camp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American soldier shortly after being beheaded in Japanese prison camp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51021 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fda78111-1ca0-4936-a72a-d6273ed234b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fda78111-1ca0-4936-a72a-d6273ed234b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fda78111-1ca0-4936-a72a-d6273ed234b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "8zeEG9TOiBMH",
        "outputId": "8a21fbd1-0d0d-4e93-eb09-09b0cb4e0306"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  265723   \n",
              "1  284269   \n",
              "2  207715   \n",
              "3  551106   \n",
              "4    8584   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \\\n",
              "0    0.0   \n",
              "1    0.0   \n",
              "2    0.0   \n",
              "3    0.0   \n",
              "4    0.0   \n",
              "\n",
              "                                                                                            text_clean  \n",
              "0  group of friends began to volunteer at homeless shelter after their neighbors protested Seeing a...  \n",
              "1  British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...  \n",
              "2  In Goodyear released kit that allows PS to be brought to heel https youtube com watch ALXulk cg ...  \n",
              "3  Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...  \n",
              "4  Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-331b9454-726b-4034-8adf-04e316736889\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>group of friends began to volunteer at homeless shelter after their neighbors protested Seeing a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>In Goodyear released kit that allows PS to be brought to heel https youtube com watch ALXulk cg ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-331b9454-726b-4034-8adf-04e316736889')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-331b9454-726b-4034-8adf-04e316736889 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-331b9454-726b-4034-8adf-04e316736889');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Comparing visually text and its clean version \n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2Ff7EiQiBH3",
        "outputId": "44995d36-f647-42da-d059-4540b21ed378"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "text          0\n",
              "label         1\n",
              "text_clean    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Checking presence of NaNs\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiS8biJ9jniB"
      },
      "source": [
        "We have no NaNs to drop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V-92IL0iBD3"
      },
      "outputs": [],
      "source": [
        "# Creating a copy of the cleaned text\n",
        "df_clean=df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9djiZOWiA_3",
        "outputId": "515a0212-9e1b-4670-fa8e-9b4f08fff345"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "of       24233\n",
              "to       24147\n",
              "in       18918\n",
              "and      16857\n",
              "for       9642\n",
              "The       8986\n",
              "on        8969\n",
              "it        8100\n",
              "is        7743\n",
              "with      6480\n",
              "from      5989\n",
              "that      5370\n",
              "this      4966\n",
              "at        4912\n",
              "his       4816\n",
              "my        4517\n",
              "by        4464\n",
              "was       4422\n",
              "you       4113\n",
              "This      4071\n",
              "after     3397\n",
              "as        3365\n",
              "an        3332\n",
              "To        3202\n",
              "has       3173\n",
              "he        3042\n",
              "are       2905\n",
              "be        2662\n",
              "have      2526\n",
              "out       2463\n",
              "It        2328\n",
              "they      2284\n",
              "like      2266\n",
              "but       2236\n",
              "their     2233\n",
              "her       2217\n",
              "Trump     2207\n",
              "up        2152\n",
              "In        2130\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(df_clean[\"text_clean\"]).split()).value_counts()\n",
        "word_freq[1:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "t_1hh6iAiA7I",
        "outputId": "cf744a57-b818-4afa-f582-d820cd563717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             index  freq\n",
              "0        Cheapjack     1\n",
              "1  Nationalisation     1\n",
              "2       Strasbourg     1\n",
              "3             zips     1\n",
              "4          Frankel     1\n",
              "5      secretariat     1\n",
              "6             NRDC     1\n",
              "7          Monsoon     1\n",
              "8         vigilant     1\n",
              "9              gpu     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-349dd658-bb7c-488c-ad36-5ef1771acf62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cheapjack</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nationalisation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Strasbourg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>zips</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Frankel</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>secretariat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NRDC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Monsoon</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>vigilant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-349dd658-bb7c-488c-ad36-5ef1771acf62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-349dd658-bb7c-488c-ad36-5ef1771acf62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-349dd658-bb7c-488c-ad36-5ef1771acf62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# list the least 10 words used and set the name of their repetition to \"freq\"\n",
        "word_freq[-10:].reset_index(name='freq')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42-dca3wiA2I",
        "outputId": "d00cb8e5-ebef-4c3b-d943-9b30c59d7891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.552117\n",
              "1.0    0.443983\n",
              "2.0    0.003900\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Checking distribution of target variable values\n",
        "\n",
        "df_clean['label'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abJk0ocdlQSQ"
      },
      "source": [
        "**Ops!** We're having binary classification problem and we're supposed to have only 2 labels but we're obviously getting 3! \n",
        "\n",
        "Of course the undefined one is the one with least distribution and since it has 0.003867, we'll drop the records which have it as their label.\n",
        "\n",
        "Also a good thing to notice is that the classes are somehow balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrF5Sq1CiAwK"
      },
      "outputs": [],
      "source": [
        "#Include in the data frame only records which lave 0 or 1 in label column\n",
        "df_clean=df_clean[(df_clean['label']==0) | (df_clean['label']==1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR7DKguoiAmo",
        "outputId": "0b960a84-2539-43a8-dd06-af02257fa54b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.554279\n",
              "1.0    0.445721\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#Checking for label column values\n",
        "\n",
        "df_clean['label'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiSmNegqoFA5"
      },
      "source": [
        " **Viola!**  It seems we got rid of the unknown class! 🙂\n",
        "\n",
        " Now, it's time for the next step.\n",
        "\n",
        "Let's checkout the most frequent and least frequent words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAHlYmOkiAe6",
        "outputId": "ea2e6273-09b2-4245-e9c6-5ddacf53d5a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "of      24197\n",
              "to      24102\n",
              "in      18891\n",
              "and     16820\n",
              "for      9621\n",
              "on       8954\n",
              "The      8893\n",
              "it       8083\n",
              "is       7718\n",
              "with     6473\n",
              "from     5985\n",
              "that     5354\n",
              "this     4954\n",
              "at       4904\n",
              "his      4808\n",
              "my       4507\n",
              "by       4458\n",
              "was      4412\n",
              "you      4092\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "#join >> enter space after each char , split >> split each character\n",
        "word_freq = pd.Series(\" \".join(df_clean[\"text_clean\"]).split()).value_counts()\n",
        "word_freq[1:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "efpXESA3h_oZ",
        "outputId": "0d88ae8f-87ea-4be7-a186-7109b315b7d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            index  freq\n",
              "0    enlightening     1\n",
              "1              Ty     1\n",
              "2      Pennington     1\n",
              "3          morphs     1\n",
              "4     unravelling     1\n",
              "5       Kilcullen     1\n",
              "6  Transcaucasian     1\n",
              "7    Byelorussian     1\n",
              "8          Ruthie     1\n",
              "9             gpu     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87e06761-115f-4696-b834-444373d9ee50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>enlightening</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ty</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pennington</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>morphs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unravelling</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kilcullen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Transcaucasian</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Byelorussian</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ruthie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87e06761-115f-4696-b834-444373d9ee50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87e06761-115f-4696-b834-444373d9ee50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87e06761-115f-4696-b834-444373d9ee50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojO5lPyScfrL"
      },
      "source": [
        "#Assigning  dependent and independent variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVE4jxkVcfXt"
      },
      "outputs": [],
      "source": [
        "X=df_clean['text_clean']\n",
        "y=df_clean['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhLbKP9CfFgN",
        "outputId": "9666fb6f-6dcb-475c-d62b-a494889fbc6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        group of friends began to volunteer at homeless shelter after their neighbors protested Seeing a...\n",
              "1        British Prime Minister Theresa May on Nerve Attack on Former Russian Spy The government has conc...\n",
              "2        In Goodyear released kit that allows PS to be brought to heel https youtube com watch ALXulk cg ...\n",
              "3        Happy Birthday Bob Barker The Price Is Right Host on How He Like to Be Remembered As the man who...\n",
              "4        Obama to Nation Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Johns...\n",
              "                                                        ...                                                 \n",
              "51015               Discussion What monitor type would you recommend for this config is bottlenecking my gpu\n",
              "51016                     British general Jeffrey Amherst Giving smallpox blankets to area natives colorized\n",
              "51017                If The Zombie Apocalypse Happens This Is Where Scientists Say You Should Go The Rockies\n",
              "51018                               The is Coming Join The One Big Union Industrial Workers of the World USA\n",
              "51019               Why the Viral United Airlines Video Kept Getting Deleted From Reddit It depicts violence\n",
              "Name: text_clean, Length: 50821, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxua9AQKputR"
      },
      "source": [
        "#Feature Creation using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AWmOuytq_sv"
      },
      "outputs": [],
      "source": [
        "# Sample data - 20% of data to validation set\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "xtr, xts, ytr, yts = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify =y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in xtr.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QwBGMOJpseM",
        "outputId": "bc080968-c7ad-4ba9-cdfe-ff6a45f02b77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "\n",
        "    # lowercase : bool, default=True\n",
        "    #     Convert all characters to lowercase before tokenizing.\n",
        "    # smooth_idf : bool, default=True\n",
        "    #     Smooth idf weights by adding one to document frequencies, as if an\n",
        "    #     extra document was seen containing every term in the collection\n",
        "    #     exactly once. Prevents zero divisions.\n",
        "vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"word\", max_df=0.3, min_df=10, ngram_range=(1, 2), norm=\"l2\"\n",
        ")\n",
        "vectorizer.fit(df_clean[\"text_clean\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHnqPfXaqEb7",
        "outputId": "efdbcd07-253f-4a69-c4d4-b7d86f02e8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique word (ngram) vector extract:\n",
            "\n",
            " it before        8026\n",
            "we do           18010\n",
            "wiped out       18460\n",
            "furniture        5802\n",
            "building and     2175\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Vector representation of vocabulary\n",
        "word_vector = pd.Series(vectorizer.vocabulary_).sample(5, random_state=5)\n",
        "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1FhumGlriYS",
        "outputId": "b6f837c4-a372-4e15-e472-e0fd2d9e60a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40656, 18970)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "xtr_vec = vectorizer.transform(xtr)\n",
        "xts_vec = vectorizer.transform(xts)\n",
        "xtr_vec.get_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZZ6C4ULr91-",
        "outputId": "b05a7f0c-c5c5-45c3-8c26-728c56e38ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:\n",
            "['These rocks at my local beach They have jagged square pattern that looks so cool guessing it from erosion from the sea']\n",
            "\n",
            "Vector representation of sentence:\n",
            "          at     at my     beach      cool      from  from the      have  \\\n",
            "0  0.107928  0.209136  0.211901  0.217699  0.203701   0.15044  0.126764   \n",
            "\n",
            "        it   it from     local    looks  looks so        my  my local  \\\n",
            "0  0.09506  0.249808  0.181366  0.16067  0.297264  0.106793  0.223643   \n",
            "\n",
            "    pattern     rocks       sea        so    square      that  that looks  \\\n",
            "0  0.247035  0.263348  0.218432  0.138628  0.238498  0.103642    0.250787   \n",
            "\n",
            "    the sea     these     they  they have  \n",
            "0  0.263348  0.161443  0.12348    0.23173  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Compare original comment text with its numeric vector representation\n",
        "print(f\"Original sentence:\\n{xtr[3:4].values}\\n\")\n",
        "# Feature Matrix\n",
        "features = pd.DataFrame(\n",
        "    xtr_vec[3:4].toarray(), columns=vectorizer.get_feature_names()\n",
        ")\n",
        "nonempty_feat = features.loc[:, (features != 0).any(axis=0)]\n",
        "print(f\"Vector representation of sentence:\\n {nonempty_feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We'll try different classifiers."
      ],
      "metadata": {
        "id": "UxRYOEl-7fmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# models to test\n",
        "classifiers = [\n",
        "    #HistGradientBoostingClassifier(),\n",
        "    LogisticRegression (random_state=22),\n",
        "    LinearSVC(random_state=1),\n",
        "    RandomForestClassifier(random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    BernoulliNB(),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12,12,12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1 ),\n",
        "        \n",
        "\n",
        "\n",
        "]\n",
        "# get names of the objects in list (too lazy for c&p...)\n",
        "names = [re.match(r\"[^\\(]+\", name.__str__())[0] for name in classifiers]\n",
        "print(f\"Classifiers to test: {names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRYnHJe17aOM",
        "outputId": "e2344b2c-3bd0-4f50-baaf-de9172488330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifiers to test: ['LogisticRegression', 'LinearSVC', 'RandomForestClassifier', 'XGBClassifier', 'BernoulliNB', 'MLPClassifier']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test all classifiers and save pred. results on test data\n",
        "results = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    clf_object=clf\n",
        "    clf.fit(xtr_vec, ytr)\n",
        "    prediction = clf.predict(xts_vec)\n",
        "    report = sklearn.metrics.classification_report(yts, prediction)\n",
        "    results[name] = report\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du0MV8yj8C7C",
        "outputId": "2f9b5b05-5bab-4252-fd4e-a407c8209ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: LinearSVC\n",
            "Training classifier: RandomForestClassifier\n",
            "Training classifier: XGBClassifier\n",
            "Training classifier: BernoulliNB\n",
            "Training classifier: MLPClassifier\n",
            "CPU times: user 1min 39s, sys: 8.06 s, total: 1min 47s\n",
            "Wall time: 1min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aidLrk9T8rWB",
        "outputId": "d6b2c2f8-6c61-4fd7-aac3-630085d00d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.83      0.83      5634\n",
            "         1.0       0.79      0.78      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n",
            "Results for LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.82      5634\n",
            "         1.0       0.77      0.78      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.82      0.81      5634\n",
            "         1.0       0.77      0.74      0.75      4531\n",
            "\n",
            "    accuracy                           0.78     10165\n",
            "   macro avg       0.78      0.78      0.78     10165\n",
            "weighted avg       0.78      0.78      0.78     10165\n",
            "\n",
            "\n",
            "Results for XGBClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.84      0.75      5634\n",
            "         1.0       0.72      0.50      0.59      4531\n",
            "\n",
            "    accuracy                           0.69     10165\n",
            "   macro avg       0.70      0.67      0.67     10165\n",
            "weighted avg       0.70      0.69      0.68     10165\n",
            "\n",
            "\n",
            "Results for BernoulliNB:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.78      0.81      5634\n",
            "         1.0       0.75      0.82      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for MLPClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.82      0.83      5634\n",
            "         1.0       0.78      0.80      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LR\", LogisticRegression())])\n",
        "\n",
        "# define parameter space to test # runtime \n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3),(1,4),(1,5)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     'LR__penalty' : ['l1', 'l2'],\n",
        "    'LR__C' : [0.1,0.5],\n",
        "    'LR__solver' : ['liblinear','sag','saga'],\n",
        "    'LR__max_iter': [100,200]\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"roc_auc\", n_iter=30,cv=pds)\n",
        "pipe_clf.fit(X, y)\n",
        "pickle.dump(pipe_clf, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vquKOoG_87vS",
        "outputId": "25d6b27e-e129-4b0a-e4b9-59ddc205e464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "3 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.8065389  0.86395898 0.86403647 0.85867683        nan 0.86737246\n",
            " 0.86095918        nan 0.8546546  0.86239159 0.88590178 0.86284533\n",
            " 0.87216432 0.85751209 0.883655   0.86407533 0.8804909  0.86595133\n",
            " 0.85172304 0.85888127 0.86668706 0.85535306 0.8114759         nan\n",
            " 0.86990015 0.86316855 0.84804095 0.85273504 0.81743526 0.86398582]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.57 s, sys: 700 ms, total: 10.3 s\n",
            "Wall time: 2min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7np6QZrgw37R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16662870-5ed6-4b87-af96-27e7e1789d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 9, 'tfidf__max_df': 0.3, 'LR__solver': 'saga', 'LR__penalty': 'l2', 'LR__max_iter': 200, 'LR__C': 0.5}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOSm3GRqo5wU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0504b192-50fe-4ff3-8330-6b7ec71058f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.87      0.87      5634\n",
            "         1.0       0.84      0.83      0.83      4531\n",
            "\n",
            "    accuracy                           0.85     10165\n",
            "   macro avg       0.85      0.85      0.85     10165\n",
            "weighted avg       0.85      0.85      0.85     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFa2NGhgo5wb"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_LogReg_trial.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with no stemming or lemmatization got testing score: 0.85176!\n",
        "\n",
        "Since the accuracy is not bad and also weird to be higher than validation set at the same time.\n",
        "Let's try with 'char' vectorizer instead of 'word' vectorizer."
      ],
      "metadata": {
        "id": "D81Qh31oLusb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4KB9s1iIERZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82eed7b1-252c-45b9-da53-06c62dba370c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "4 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.75698341 0.8511296  0.8568362  0.85651337 0.74542432 0.86502395\n",
            "        nan 0.86897746 0.77663835 0.75273635 0.84864951 0.86911484\n",
            "        nan 0.84718537 0.85198436 0.84893602        nan 0.85675852\n",
            " 0.84974456 0.85084744 0.8486166  0.84873048 0.8651294  0.84760813\n",
            " 0.86502395 0.84997407 0.85658772        nan 0.75997195 0.86753855]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.1 s, sys: 1.66 s, total: 27.8 s\n",
            "Wall time: 12min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer='char')), (\"LR\", LogisticRegression())])\n",
        "\n",
        "# define parameter space to test # runtime \n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 4), (1, 5)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     'LR__penalty' : ['l1', 'l2'],\n",
        "    'LR__C' : [0.1,0.5],\n",
        "    'LR__solver' : ['liblinear','sag','saga'],\n",
        "    'LR__max_iter': [100,200]\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"roc_auc\", n_iter=30,cv=pds)\n",
        "pipe_clf.fit(X, y)\n",
        "pickle.dump(pipe_clf, open(\"./clf_pipe.pck\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txfQSwDmIERi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e7768c-c425-482f-d93b-c970197c9888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 17, 'tfidf__max_df': 0.3, 'LR__solver': 'sag', 'LR__penalty': 'l2', 'LR__max_iter': 100, 'LR__C': 0.5}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-d0s2uSIERi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300cf412-9c04-45ee-bc26-95040fdeb306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.85      0.84      5634\n",
            "         1.0       0.81      0.80      0.80      4531\n",
            "\n",
            "    accuracy                           0.83     10165\n",
            "   macro avg       0.82      0.82      0.82     10165\n",
            "weighted avg       0.83      0.83      0.83     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HELJDzS0IERi"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_LogReg_trial_char.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using character vectorizer got us testing accuracy of 0.83334\n",
        "\n",
        "#Observation 1: Using word vectorizer was better by almost 2 pecent."
      ],
      "metadata": {
        "id": "r52Z5JXDfTm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's try stemming preprocessing with Logistic Regression!\n",
        "Expectation: Higher accuracy!"
      ],
      "metadata": {
        "id": "RTFqGDFXaE_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Cleaning using stemming \n",
        "df[\"text_clean\"] = df.loc[df_main[\"text\"].str.len() > 10, \"text\"]\n",
        "df[\"text_clean\"] = df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x,stem=True, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n"
      ],
      "metadata": {
        "id": "HFyvaLPW_MhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfb7e18-8ea1-4e45-b019-98e1e1d2d874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.5 s, sys: 39.9 ms, total: 21.5 s\n",
            "Wall time: 21.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning values to dependent and independent variables once more.\n",
        "X=df_clean['text_clean']\n",
        "y=df_clean['label']"
      ],
      "metadata": {
        "id": "xCzfbAsgN4Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data - 20% of data to validation set\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "xtr, xts, ytr, yts = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify =y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in xtr.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "iuXmLX-dOAh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330aef61-bd3c-4b4e-ec3b-bfb1a88c1f4b",
        "id": "tLiwK7NjcGRa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.83      0.83      5634\n",
            "         1.0       0.79      0.78      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n",
            "Results for LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.82      5634\n",
            "         1.0       0.77      0.78      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.82      0.81      5634\n",
            "         1.0       0.77      0.74      0.75      4531\n",
            "\n",
            "    accuracy                           0.78     10165\n",
            "   macro avg       0.78      0.78      0.78     10165\n",
            "weighted avg       0.78      0.78      0.78     10165\n",
            "\n",
            "\n",
            "Results for XGBClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.84      0.75      5634\n",
            "         1.0       0.72      0.50      0.59      4531\n",
            "\n",
            "    accuracy                           0.69     10165\n",
            "   macro avg       0.70      0.67      0.67     10165\n",
            "weighted avg       0.70      0.69      0.68     10165\n",
            "\n",
            "\n",
            "Results for BernoulliNB:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.78      0.81      5634\n",
            "         1.0       0.75      0.82      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for MLPClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.82      0.83      5634\n",
            "         1.0       0.78      0.80      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LR\", LogisticRegression())])\n",
        "\n",
        "# define parameter space to test # runtime \n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3),(1,4),(1,5)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     'LR__penalty' : ['l1', 'l2'],\n",
        "    'LR__C' : [0.1,0.5],\n",
        "    'LR__solver' : ['liblinear','sag','saga'],\n",
        "    'LR__max_iter': [100,200]\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"roc_auc\", n_iter=30,cv=pds)\n",
        "pipe_clf.fit(X, y)\n",
        "pickle.dump(pipe_clf, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b4d62d-547d-4819-fd11-82d0e3d569dd",
        "id": "LmVgsvI4cGRf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "2 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.86505611 0.79528201 0.81541422 0.86396278 0.80396485 0.85972628\n",
            " 0.85626262 0.81402094 0.85438431 0.86510838 0.85372573 0.81423283\n",
            " 0.80250306 0.86727155 0.8507875  0.85712009 0.85827957 0.86299491\n",
            " 0.79605494 0.87901599 0.85678414        nan 0.85045911 0.87133475\n",
            "        nan 0.86737551 0.85542643 0.86333307 0.85629232 0.86856622]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.79 s, sys: 798 ms, total: 7.58 s\n",
            "Wall time: 2min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babd822c-1013-468b-d8d8-bb906dc94dc5",
        "id": "NC0Rs7k6cGRf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 35, 'tfidf__max_df': 0.3, 'LR__solver': 'liblinear', 'LR__penalty': 'l2', 'LR__max_iter': 100, 'LR__C': 0.5}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc09fe5-4b76-42d6-cae4-1bfc5c218553",
        "id": "IlVodm_dcGRg"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.85      0.85      5634\n",
            "         1.0       0.81      0.80      0.81      4531\n",
            "\n",
            "    accuracy                           0.83     10165\n",
            "   macro avg       0.83      0.83      0.83     10165\n",
            "weighted avg       0.83      0.83      0.83     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVc660UfcGRg"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_LogReg_trial_stemming.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation 2\n",
        "A bit higher accuracy with stemming of value 0.85609!"
      ],
      "metadata": {
        "id": "IOG0SGDzcpkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's try lemmatization with Logistic Regression"
      ],
      "metadata": {
        "id": "CQRm03sYxI4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Cleaning using stemming \n",
        "df[\"text_clean\"] = df.loc[df_main[\"text\"].str.len() > 10, \"text\"]\n",
        "df[\"text_clean\"] = df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x,stem=False, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147d9c15-e31c-4bf1-fc58-c9d19dfa754b",
        "id": "bE4sI92wxG9M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 s, sys: 58.2 ms, total: 13.5 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning values to dependent and independent variables once more.\n",
        "X=df_clean['text_clean']\n",
        "y=df_clean['label']"
      ],
      "metadata": {
        "id": "gUPuethZxG9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data - 20% of data to validation set\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "xtr, xts, ytr, yts = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify =y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in xtr.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "roW6ISvwxG9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e3777d-accf-4fe7-817f-b55e0a627f2b",
        "id": "Y-E2OshvxG9Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.83      0.83      5634\n",
            "         1.0       0.79      0.78      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n",
            "Results for LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.82      5634\n",
            "         1.0       0.77      0.78      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.82      0.81      5634\n",
            "         1.0       0.77      0.74      0.75      4531\n",
            "\n",
            "    accuracy                           0.78     10165\n",
            "   macro avg       0.78      0.78      0.78     10165\n",
            "weighted avg       0.78      0.78      0.78     10165\n",
            "\n",
            "\n",
            "Results for XGBClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.84      0.75      5634\n",
            "         1.0       0.72      0.50      0.59      4531\n",
            "\n",
            "    accuracy                           0.69     10165\n",
            "   macro avg       0.70      0.67      0.67     10165\n",
            "weighted avg       0.70      0.69      0.68     10165\n",
            "\n",
            "\n",
            "Results for BernoulliNB:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.78      0.81      5634\n",
            "         1.0       0.75      0.82      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for MLPClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.82      0.83      5634\n",
            "         1.0       0.78      0.80      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"LR\", LogisticRegression())])\n",
        "\n",
        "# define parameter space to test # runtime \n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3),(1,4),(1,5)],\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "     'LR__penalty' : ['l1', 'l2'],\n",
        "    'LR__C' : [0.1,0.5],\n",
        "    'LR__solver' : ['liblinear','sag','saga'],\n",
        "    'LR__max_iter': [100,200]\n",
        "}\n",
        "# it is quite slow so we do 4 for now\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, n_jobs=-1, scoring=\"roc_auc\", n_iter=30,cv=pds)\n",
        "pipe_clf.fit(X, y)\n",
        "pickle.dump(pipe_clf, open(\"./clf_pipe.pck\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea3576d-40b6-4933-b8ac-fdce18d7a061",
        "id": "8cHRpHexxG9Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "5 fits failed out of a total of 30.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.8598751  0.86057454 0.86213238 0.88017195 0.79636014\n",
            " 0.86524551 0.86511056 0.88549206 0.86873337 0.81800956        nan\n",
            " 0.81853425 0.86397058 0.86931126 0.88328258 0.86352753 0.86063941\n",
            "        nan 0.85134936 0.85375268 0.81507451 0.8528886  0.86915552\n",
            " 0.85522465        nan 0.86293014        nan 0.86112508 0.85398619]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.9 s, sys: 1.73 s, total: 17.7 s\n",
            "Wall time: 3min 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d48bae-f960-45d8-fb75-827b85768051",
        "id": "P-qzHZaAxG9Z"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 5), 'tfidf__min_df': 11, 'tfidf__max_df': 0.3, 'LR__solver': 'liblinear', 'LR__penalty': 'l2', 'LR__max_iter': 200, 'LR__C': 0.5}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b198d80-2eeb-4a41-8c23-377d73cf1d32",
        "id": "yXaWe8aSxG9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.87      0.86      5634\n",
            "         1.0       0.83      0.83      0.83      4531\n",
            "\n",
            "    accuracy                           0.85     10165\n",
            "   macro avg       0.85      0.85      0.85     10165\n",
            "weighted avg       0.85      0.85      0.85     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbgwIOqWxG9a"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_LogReg_trial_lemm.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation 3\n",
        "Logistic Regression with lemmatization score: 0.85265!"
      ],
      "metadata": {
        "id": "KA_2BYAj8P6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#One more trial with XGBoostClassifier!\n",
        "Expectation: Can not expect higher accuracy than logistic Regression but let's find out. We'll try it with RandomSearch, trying different hyperparameters including vectorization techniques. This will take alot of time but worth trying! "
      ],
      "metadata": {
        "id": "bxHIPF_Fcjbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Cleaning using stemming \n",
        "df[\"text_clean\"] = df.loc[df_main[\"text\"].str.len() > 10, \"text\"]\n",
        "df[\"text_clean\"] = df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x,stem=False, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d615e8-af51-48d2-e11d-2f53b236b14d",
        "id": "QyzZuo2bjOmp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 s, sys: 53.9 ms, total: 13.5 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning values to dependent and independent variables once more.\n",
        "X=df_clean['text_clean']\n",
        "y=df_clean['label']"
      ],
      "metadata": {
        "id": "6LN8fTSRjOm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data - 20% of data to validation set\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "xtr, xts, ytr, yts = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify =y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in xtr.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "t10cL0LUjOm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254e0ace-321c-4c8c-e014-6348b977ee5a",
        "id": "jZi_lkbJjOm1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for LogisticRegression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.83      0.83      5634\n",
            "         1.0       0.79      0.78      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n",
            "Results for LinearSVC:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.81      0.82      5634\n",
            "         1.0       0.77      0.78      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for RandomForestClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      0.82      0.81      5634\n",
            "         1.0       0.77      0.74      0.75      4531\n",
            "\n",
            "    accuracy                           0.78     10165\n",
            "   macro avg       0.78      0.78      0.78     10165\n",
            "weighted avg       0.78      0.78      0.78     10165\n",
            "\n",
            "\n",
            "Results for XGBClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.84      0.75      5634\n",
            "         1.0       0.72      0.50      0.59      4531\n",
            "\n",
            "    accuracy                           0.69     10165\n",
            "   macro avg       0.70      0.67      0.67     10165\n",
            "weighted avg       0.70      0.69      0.68     10165\n",
            "\n",
            "\n",
            "Results for BernoulliNB:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.78      0.81      5634\n",
            "         1.0       0.75      0.82      0.78      4531\n",
            "\n",
            "    accuracy                           0.80     10165\n",
            "   macro avg       0.80      0.80      0.80     10165\n",
            "weighted avg       0.80      0.80      0.80     10165\n",
            "\n",
            "\n",
            "Results for MLPClassifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.82      0.83      5634\n",
            "         1.0       0.78      0.80      0.79      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hQynyx7aAs8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07d1cb3-e618-4419-8dae-9adca014c6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9min 23s, sys: 3.67 s, total: 9min 27s\n",
            "Wall time: 1h 6min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"xgb\", XGBClassifier())])\n",
        "\n",
        "# define parameter space to test # runtime 19min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1,2),(1, 3),(1,4),(1,5)],\n",
        "    \"tfidf__analyzer\" : ['word', 'char'],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [10],\n",
        "    \"xgb__n_estimators\":[200,300,400],\n",
        "    \"xgb__max_depth\":[30,40,50],\n",
        "\n",
        "}\n",
        "pipe_xgb_clf = RandomizedSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\",  n_iter=3, cv=pds)\n",
        "pipe_xgb_clf.fit(X, y)\n",
        "pickle.dump(pipe_xgb_clf, open(\"./pipe_xgb_clf.pck\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vxZQXiraAs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c4ce7a-c436-45ac-b05f-e5d134641f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'xgb__n_estimators': 200, 'xgb__max_depth': 50, 'tfidf__ngram_range': (1, 4), 'tfidf__min_df': 10, 'tfidf__max_df': 0.5, 'tfidf__analyzer': 'word'}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_xgb_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7J2nePgaAs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38e845c-c12d-493f-b48f-6e73274c34a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      5634\n",
            "         1.0       0.99      0.99      0.99      4531\n",
            "\n",
            "    accuracy                           0.99     10165\n",
            "   macro avg       0.99      0.99      0.99     10165\n",
            "weighted avg       0.99      0.99      0.99     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X,y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IQ_Iw2WaAs_"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_xgb_trial.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation 4\n",
        "XGBclassifier got testing score:0.83706!\n",
        "\n",
        "The model is definetely overfitting\n"
      ],
      "metadata": {
        "id": "T3zWvL6LjOm3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RqukUg6xrna"
      },
      "source": [
        "# One trial with MLP Classifier\n",
        "We'll apply lemmatization and RandomSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Cleaning using stemming \n",
        "df[\"text_clean\"] = df.loc[df_main[\"text\"].str.len() > 10, \"text\"]\n",
        "df[\"text_clean\"] = df[\"text_clean\"].map(\n",
        "    lambda x: clean_text(x,stem=False, for_embedding=False) if isinstance(x, str) else x\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03801bb6-d1ad-4fd2-c7e3-b18a96957c70",
        "id": "Vdf80MjdqCGV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 s, sys: 44.1 ms, total: 13.5 s\n",
            "Wall time: 13.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning values to dependent and independent variables once more.\n",
        "X=df_clean['text_clean']\n",
        "y=df_clean['label']"
      ],
      "metadata": {
        "id": "M212oyZKqCGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data - 20% of data to validation set\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "\n",
        "# Further split the original training set to a train and a validation set\n",
        "xtr, xts, ytr, yts = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify =y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in xtr.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)"
      ],
      "metadata": {
        "id": "SvFLjBmoqCGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGEY9DQpu8OB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ba3ecf-e958-482d-ea72-14cdc5dd5d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 14s, sys: 57 s, total: 2min 11s\n",
            "Wall time: 5min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# feature creation and modelling in a single function\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"mlp\", MLPClassifier())])\n",
        "\n",
        "# define parameter space to test # runtime 19min\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1,2),(1, 3)],\n",
        "    \"tfidf__analyzer\" : ['word', 'char'],\n",
        "    \"tfidf__max_df\": [0.5],\n",
        "    \"tfidf__min_df\": [10],\n",
        "    \"mlp__hidden_layer_sizes\": [128],\n",
        "    \"mlp__solver\":['adam','sgd'] ,\n",
        "    \"mlp__batch_size\":[128] ,\n",
        "    \"mlp__early_stopping\":[True] \n",
        "}\n",
        "pipe_mlp_clf = RandomizedSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\",  n_iter=3, cv=pds)\n",
        "pipe_mlp_clf.fit(X, y)\n",
        "pickle.dump(pipe_mlp_clf, open(\"./pipe_mlp_clf.pck\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUPvlsp-vD5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019f8be4-cd60-4a63-cce2-71d4d666ec41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 10, 'tfidf__max_df': 0.5, 'tfidf__analyzer': 'char', 'mlp__solver': 'adam', 'mlp__hidden_layer_sizes': 128, 'mlp__early_stopping': True, 'mlp__batch_size': 128}\n"
          ]
        }
      ],
      "source": [
        "best_params = pipe_mlp_clf.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sf-cSSsLuNa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f621e44-2a25-45c5-8bc8-a186205e145c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.84      0.83      5634\n",
            "         1.0       0.79      0.78      0.78      4531\n",
            "\n",
            "    accuracy                           0.81     10165\n",
            "   macro avg       0.81      0.81      0.81     10165\n",
            "weighted avg       0.81      0.81      0.81     10165\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(xts)\n",
        "report = sklearn.metrics.classification_report(yts, pipe_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jfrDUwW7IZm"
      },
      "outputs": [],
      "source": [
        "submission= pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test.index\n",
        "\n",
        "submission['label']=pipe.predict_proba(df_test['text']) [:,1]\n",
        "\n",
        "submission.to_csv('submission_mlp_trial.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY59sWpnwgOi"
      },
      "source": [
        "#Observation 5:\n",
        "\n",
        "MLP got testing score: 0.74576\n",
        "The model is seems to have both high variance and high bias."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final conclusion:\n",
        "Best model used was Logistic Regressesion with stemming preprocessing and word vectorizer."
      ],
      "metadata": {
        "id": "2zOCChiqLXuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#✔️ Answer the questions below (briefly):\n",
        "\n",
        "🌈 What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "> Answer:  n-gram is a contiguous sequence of n items from a given sample of text or speech. \n",
        "Word N-gram is number of words subsequent each time from a sentence.\n",
        "Character n-gram is the number of subsequent of characters taken from sentence each time.\n",
        "\n",
        "> I think Character N-gram is more susibtible to out-of-vocabulary issue because it is not necessary that every time we split characters they would give meaningful word.\n",
        "\n",
        "🌈 What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
        "\n",
        "> Stop word removal is removing the words that occur in all the documents with high frequency but stemming is removing part of the word/verb which is inflection and are considered unnecessary characters. Yes, they are language dependent as every language has its own rules of language even if some of them overlap on fews rules, others could be completely different.   \n",
        "\n",
        "🌈 Is tokenization techniques language dependent? Why?\n",
        "\n",
        "> Yes they are language specific because tokenization can be done to either separate words or sentences and each language has is own rules.\n",
        "\n",
        "🌈 What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "\n",
        "> Count Vectorizer is a way to convert a given set of strings into a frequency representation.\n",
        "\n",
        "> TF-IDF means Term Frequency - Inverse Document Frequency. This is a statistic that is based on the frequency of a word in the corpus but it also provides a numerical representation of how important a word is for statistical analysis.\n",
        " TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. We can then remove the words that are less important for analysis, hence making the model building less complex by reducing the input dimensions.\n",
        "\n",
        "\n",
        "> No, it will not be feasible to use all possible N-grams as this will need alot of computational power and time. I think the best way to get the best N-grams is trying different values in hyperparameter tuning technique like GridSearch (maybe not feasible) or RandomSearch.\n",
        "\n",
        "References: \n",
        "\n",
        "\n",
        "https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
        "\n",
        "https://www.linkedin.com/pulse/count-vectorizers-vs-tfidf-natural-language-processing-sheel-saket"
      ],
      "metadata": {
        "id": "EDitCu4XkUVW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pj5CP_X2K9eC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}